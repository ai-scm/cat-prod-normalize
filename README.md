# üöÄ Cat Prod Normalize - Multi-Stack Data Pipeline

Sistema ETL completo para el procesamiento automatizado de conversaciones del chatbot **Catia**, implementado con AWS CDK como pipeline de datos empresarial.

Este proyecto implementa un **sistema de an√°lisis multi-fuente** para conversaciones del chatbot Catia, con dos pipelines independientes: uno para an√°lisis de conversaciones y feedback, y otro para an√°lisis de costos de tokens de Amazon Bedrock Claude Sonnet 3.5.

### üéØ **Objetivos del Sistema**
- **Pipeline ETL Principal**: Conversaciones DynamoDB ‚Üí S3 ‚Üí Athena (Stacks 1-2)
- **Pipeline Tokens Independiente**: An√°lisis de costos Claude Sonnet 3.5 (Stack 3)
- **An√°lisis de Costos Bedrock**: C√°lculo de tokens y estimaciones de costos AWS
- **Optimizaci√≥n de Datos**: Conversi√≥n CSV ‚Üí Parquet para consultas eficientes
- **Escalabilidad**: Arquitectura serverless multi-stack independiente
- **Monitoreo**: Tags detallados para Cost Explorer y billing por componente

## üèóÔ∏è Arquitectura Multi-Stack Independiente

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        üîÑ PIPELINE PRINCIPAL (Stacks 1-2)                   ‚îÇ
‚îÇ                           An√°lisis de Conversaciones                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DynamoDB-1  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Lambda ETL-1‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   S3 CSV    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Glue ETL-2  ‚îÇ
‚îÇConversations‚îÇ    ‚îÇ(Normalize)  ‚îÇ    ‚îÇ Raw Reports ‚îÇ    ‚îÇ(Transform)  ‚îÇ
‚îÇ    Table    ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ                                        ‚îÇ
                           ‚ñº                                        ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇEventBridge  ‚îÇ                          ‚îÇ S3 Parquet  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ Athena
                   ‚îÇ Scheduler   ‚îÇ                          ‚îÇOptimized DB ‚îÇ     Analytics
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                    ‚îÇ
                                                                    ‚ñº
                                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                            ‚îÇGlue Crawler ‚îÇ
                                                            ‚îÇAuto-Schema  ‚îÇ
                                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          PIPELINE Tokens (Stack 3)                 ‚îÇ
‚îÇ                    An√°lisis de Tokens Amazon Bedrock                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DynamoDB-2  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Lambda    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ S3 Tokens   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ Athena
‚îÇ   Bedrock   ‚îÇ    ‚îÇ   Tokens    ‚îÇ    ‚îÇ  Reports    ‚îÇ     Analytics
‚îÇConversations‚îÇ    ‚îÇ (Claude)    ‚îÇ    ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇEventBridge  ‚îÇ
                   ‚îÇIndependent  ‚îÇ
                   ‚îÇ Scheduler   ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Estructura del Proyecto

```
cat-prod-normalize/
‚îú‚îÄ‚îÄ üìì notebook/                                    # C√≥digo origen de referencia
‚îÇ   ‚îú‚îÄ‚îÄ cat-prod-normalize-data.ipynb               # Notebook original
‚îÇ   ‚îî‚îÄ‚îÄ cat_prod_normalize_script.py                # Script convertido
‚îú‚îÄ‚îÄ üêç lambda/                                      # Funciones Lambda multi-ETL
‚îÇ   ‚îú‚îÄ‚îÄ README.md                                   # Documentaci√≥n ETL espec√≠fica
‚îÇ   ‚îú‚îÄ‚îÄ etl-process1/                               # üîÑ ETL-1: Extracci√≥n y normalizaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lambda_function.py                      # Core: DynamoDB ‚Üí CSV
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                        # pandas, boto3, numpy
‚îÇ   ‚îú‚îÄ‚îÄ etl-process2/                               # üîÑ ETL-2: Transformaci√≥n a Parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ glue_job_script.py                      # Glue: CSV ‚Üí Parquet + tokens
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                        # tiktoken, pyspark
‚îÇ   ‚îî‚îÄ‚îÄ tokens-process/                             # üí∞ An√°lisis de costos
‚îÇ       ‚îú‚îÄ‚îÄ tokens_lambda.py                        # Tokens GPT + c√°lculo costos
‚îÇ       ‚îî‚îÄ‚îÄ requirements.txt                        # pandas, boto3
‚îú‚îÄ‚îÄ üìö lib/                                         # Definiciones CDK (3 stacks)
‚îÇ   ‚îú‚îÄ‚îÄ constructs/                                 # Componentes reutilizables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ athena-construct.ts                     # WorkGroup Athena
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ catalog-construct.ts                    # Glue Database + Crawler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator-construct.ts               # EventBridge automation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transform-job-construct.ts              # Glue Job ETL-2
‚îÇ   ‚îî‚îÄ‚îÄ stacks/                                     # üèóÔ∏è 3 Stacks principales
‚îÇ       ‚îú‚îÄ‚îÄ cat-prod-normalize-stack.ts             # Stack 1: ETL-1 (Lambda)
‚îÇ       ‚îú‚îÄ‚îÄ cad-prod-etl-stack.ts                   # Stack 2: ETL-2 (Glue)
‚îÇ       ‚îî‚îÄ‚îÄ cat-prod-tokens-stack.ts                # Stack 3: Tokens (Lambda)
‚îú‚îÄ‚îÄ üéØ bin/                                         # Punto de entrada
‚îÇ   ‚îî‚îÄ‚îÄ cat-prod-normalize.ts                       # App CDK multi-stack
‚îú‚îÄ‚îÄ ‚öôÔ∏è config/                                      # Configuraci√≥n centralizada
‚îÇ   ‚îú‚îÄ‚îÄ accountConfig.json                          # Cuenta AWS (081899001252)
‚îÇ   ‚îú‚îÄ‚îÄ config.json                                 # Namespace (cat-prod)
‚îÇ   ‚îî‚îÄ‚îÄ tags.json                                   # Tags est√°ndar (P0260)
‚îú‚îÄ‚îÄ üß™ test/                                        # Tests unitarios
‚îÇ   ‚îî‚îÄ‚îÄ cat-prod-normalize.test.ts                  # Tests CDK
‚îî‚îÄ‚îÄ üìã archivos ra√≠z
    ‚îú‚îÄ‚îÄ README.md                                   # Este archivo
    ‚îú‚îÄ‚îÄ package.json                                # Dependencias Node.js
    ‚îú‚îÄ‚îÄ cdk.json                                    # Configuraci√≥n CDK
    ‚îú‚îÄ‚îÄ tsconfig.json                               # TypeScript config
    ‚îî‚îÄ‚îÄ test_token_functions.py                     # Test tokens local
```

## üè≠ Stacks y Recursos Desplegados

### **üîÑ Stack 1: `cat-prod-normalize-stack` (ETL-1)**
**Prop√≥sito**: Extracci√≥n y normalizaci√≥n desde DynamoDB

| Recurso | Nombre | Descripci√≥n |
|---------|---------|-------------|
| üêç **Lambda** | `cat-prod-lambda-normalize` | ETL-1: DynamoDB ‚Üí CSV (12 columnas) |
| üì¶ **S3 Bucket** | `cat-prod-normalize-reports` | Data Lake central |
| üîê **IAM Role** | `CatProdNormalizeETLLambdaRole` | Permisos DynamoDB + S3 |
| ‚è∞ **EventBridge** | `cat-prod-daily-etl-schedule` | Trigger diario 11:30 PM COL |
| üìä **Layer** | `AWSSDKPandas-Python39:13` | Dependencias (pandas, boto3) |

### **üîÑ Stack 2: `cat-prod-etl2-stack` (ETL-2)**
**Prop√≥sito**: Transformaci√≥n a formato anal√≠tico optimizado

| Recurso | Nombre | Descripci√≥n |
|---------|---------|-------------|
| ‚ö° **Glue Job** | `cat-prod-etl2-parquet` | ETL-2: CSV ‚Üí Parquet + tokens |
| üï∑Ô∏è **Glue Crawler** | `curated-crawler` | Auto-detecci√≥n de esquemas |
| üóÑÔ∏è **Glue Database** | `cat_prod_analytics_db` | Cat√°logo de metadatos |
| üîç **Athena WorkGroup** | `wg-cat-prod-analytics` | Consultas SQL optimizadas |
| üîê **IAM Roles** | Multiple | Permisos Glue + S3 + EventBridge |
| üéØ **EventBridge** | `S3 Object Created` | Trigger autom√°tico ETL-2 |

### **üí∞ Stack 3: `cat-prod-tokens-stack` (An√°lisis tokens)**
**Prop√≥sito**: An√°lisis de tokens Amazon Bedrock Claude Sonnet 3.5

| Recurso | Nombre | Descripci√≥n |
|---------|---------|-------------|
| üêç **Lambda** | `cat-prod-lambda-tokens` | An√°lisis tokens Claude + costos |
| üìä **Layer** | `cat-prod-pandas-numpy-layer` | pandas, numpy, boto3 |
| üîê **IAM Role** | `CatProdTokensLambdaRole` | DynamoDB Bedrock + S3 + Athena |
| ‚è∞ **EventBridge** | `cat-prod-daily-tokens-schedule` | An√°lisis diario independiente |
| üóÑÔ∏è **Data Source** | `BedrockChatStack-DatabaseConversationTable` | **Tabla independiente** |

### **üéØ Fase 1: ETL-1 (Lambda Normalize)**
1. **Trigger**: EventBridge Schedule `cron(30 4 * * ? *)` (UTC)
2. **Fuente**: DynamoDB `BedrockChatStack-DatabaseConversationTable03F3FD7A-VCTDHISEE1NF`
3. **Procesamiento**: 
   - Normalizaci√≥n de usuarios √∫nicos por `user_id`
   - Extracci√≥n de preguntas desde JSON `conversation_history`
   - Clasificaci√≥n de feedback: `like/dislike/mixed`
   - Merge de tablas conversations + feedback
4. **Salida**: `s3://cat-prod-normalize-reports/reports/etl-process1/data_YYYYMMDD.csv`

### **üéØ Fase 2: ETL-2 (Glue Transform)**
1. **Trigger**: S3 Event `ObjectCreated` en `/etl-process1/`
2. **Motor**: Glue Job con Spark (2 workers G.1X)
3. **Procesamiento**:
   - Lectura CSV m√°s reciente con PySpark
   - Conversi√≥n de tipos de datos optimizada
   - **C√°lculo de tokens** con biblioteca `tiktoken`
   - Generaci√≥n de archivo Parquet √∫nico
4. **Salida**: `s3://cat-prod-normalize-reports/reports/etl-process2/data.parquet`

### **üéØ Fase 3: Catalogaci√≥n Autom√°tica**
1. **Trigger**: Glue Job State Change ‚Üí `SUCCEEDED`
2. **Acci√≥n**: Crawler escanea `/etl-process2/data.parquet/`
3. **Resultado**: Schema actualizado en `cat_prod_analytics_db`
4. **Disponibilidad**: Tabla lista para consultas Athena

### **üéØ Fase 4: An√°lisis de Tokens Bedrock (Lambda Independiente)**
1. **Trigger**: EventBridge Schedule independiente `cron(30 4 * * ? *)`
2. **Fuente**: DynamoDB `BedrockChatStack-DatabaseConversationTable03F3FD7A-VCTDHISEE1NF` **(independiente)**
3. **Procesamiento**:
   - An√°lisis de consumo tokens **Claude Sonnet 3.5** por conversaci√≥n
   - C√°lculo aproximado: `LENGTH(text) / 4` (est√°ndar Amazon Bedrock)
   - Estimaci√≥n de costos **Amazon Bedrock Claude Sonnet 3.5**
   - Estad√≠sticas agregadas por usuario/fecha
4. **Salida**: `s3://cat-prod-normalize-reports/tokens-analysis/tokens_YYYYMMDD.csv`

> **üìù Nota Importante**: El Stack 3 (Tokens) es **completamente independiente** de los Stacks 1-2. Usa una tabla DynamoDB diferente y se enfoca √∫nicamente en an√°lisis de costos de Amazon Bedrock Claude Sonnet 3.5, no en el procesamiento de conversaciones del chatbot Catia.

## üìä Esquema de Datos Final

### **üóÇÔ∏è Columnas del Dataset Principal (12 campos)**

| # | Columna | Tipo | Descripci√≥n | Origen |
|---|---------|------|-------------|--------|
| 1 | `usuario_id` | String | ID √∫nico del usuario | DynamoDB |
| 2 | `nombre` | String | Nombre completo del usuario | DynamoDB |
| 3 | `gerencia` | String | Gerencia/departamento | DynamoDB |
| 4 | `ciudad` | String | Ciudad del usuario | DynamoDB |
| 5 | `fecha_primera_conversacion` | Date | Primera interacci√≥n (DD/MM/YYYY) | Calculado |
| 6 | `numero_conversaciones` | Integer | Total conversaciones del usuario | Calculado |
| 7 | `conversacion_completa` | JSON | Historia completa de mensajes | DynamoDB |
| 8 | `feedback_total` | JSON | Datos brutos de feedback | DynamoDB |
| 9 | `numero_feedback` | Integer | Cantidad de feedbacks dados | Calculado |
| 10 | `pregunta_conversacion` | String | Preguntas extra√≠das del usuario | Extra√≠do |
| 11 | `feedback` | String | Clasificaci√≥n: like/dislike/mixed | Calculado |
| 12 | `respuesta_feedback` | String | Comments y options del feedback | Extra√≠do |

### **üí∞ Dataset de An√°lisis de Tokens Amazon Bedrock Claude Sonnet 3.5**

| Campo | Descripci√≥n | C√°lculo |
|-------|-------------|---------|
| `conversation_id` | ID √∫nico de conversaci√≥n Bedrock | DynamoDB PK |
| `user_id` | Usuario que realiz√≥ la conversaci√≥n | DynamoDB |
| `fecha` | Fecha de la conversaci√≥n | timestamp |
| `token_pregunta` | Tokens de entrada (input) | `LENGTH(user + system + chunks) / 4` |
| `token_respuesta` | Tokens de salida (output) | `LENGTH(assistant) / 4` |
| `tokens_total` | Total tokens consumidos | input + output |
| `costo_estimado_usd` | Costo estimado en USD | **Tarifa Amazon Bedrock Claude Sonnet 3.5** * tokens |
| `modelo` | Modelo utilizado | `claude-3-5-sonnet-20240620-v1:0` |
| `region` | Regi√≥n AWS | `us-east-1` |

> **‚ö†Ô∏è Fuente de Datos**: Este an√°lisis usa la tabla DynamoDB de **Amazon Bedrock** (`BedrockChatStack-DatabaseConversationTable03F3FD7A-VCTDHISEE1NF`), **NO** la tabla del chatbot Catia (`cat-prod-catia-conversations-table`).

## üöÄ Instalaci√≥n y Despliegue

### **üìã Prerrequisitos**
- **Node.js** >= 18.0.0
- **AWS CLI** configurado con cuenta `081899001252`
- **CDK CLI** instalado: `npm install -g aws-cdk`
- **Permisos IAM** para crear recursos Lambda, S3, Glue, Athena

### **‚öôÔ∏è Configuraci√≥n (Ya incluida)**
Los archivos est√°n preconfigurados en `config/`:
- `accountConfig.json`: Cuenta AWS `081899001252` + regi√≥n `us-east-1`
- `config.json`: Namespace `cat-prod` para nomenclatura
- `tags.json`: Tags corporativos (ProjectId: P0260, Env: PROD, Client: CAT)

### **üîß Pasos de Instalaci√≥n**

```bash
# 1. Clonar y preparar dependencias
npm install

# 2. Compilar TypeScript
npm run build

# 3. Verificar s√≠ntesis (sin desplegar)
npx cdk synth

# 4. Bootstrap CDK (solo primera vez)
npx cdk bootstrap

# 5. Desplegar en orden espec√≠fico
npx cdk deploy cat-prod-normalize-stack      # Stack 1: ETL-1 Lambda
npx cdk deploy cat-prod-etl2-stack           # Stack 2: ETL-2 Glue  
npx cdk deploy cat-prod-tokens-stack         # Stack 3: Tokens Analysis

# 6. Verificar recursos creados
npx cdk list
```

### **üèóÔ∏è Recursos Desplegados por Stack**

**Stack 1** (`cat-prod-normalize-stack`):
- ‚úÖ S3 Bucket: `cat-prod-normalize-reports`
- ‚úÖ Lambda: `cat-prod-lambda-normalize` (1024MB, 15min timeout)
- ‚úÖ EventBridge: `cat-prod-daily-etl-schedule` (11:30 PM COL)
- ‚úÖ IAM Role: Permisos DynamoDB + S3

**Stack 2** (`cat-prod-etl2-stack`):
- ‚úÖ Glue Job: `cat-prod-etl2-parquet` (Spark 2x G.1X)
- ‚úÖ Glue Database: `cat_prod_analytics_db`
- ‚úÖ Glue Crawler: `curated-crawler` (auto-schema)
- ‚úÖ Athena WorkGroup: `wg-cat-prod-analytics`
- ‚úÖ EventBridge: S3 Object Created trigger

**Stack 3** (`cat-prod-tokens-stack`) - **INDEPENDIENTE**:
- ‚úÖ Lambda: `cat-prod-lambda-tokens` (512MB, 1min timeout)
- ‚úÖ Lambda Layer: `cat-prod-pandas-numpy-layer`
- ‚úÖ EventBridge: `cat-prod-daily-tokens-schedule` (independiente)
- ‚úÖ IAM Role: DynamoDB Bedrock + S3 + Athena permisos
- ‚úÖ **Data Source**: `BedrockChatStack-DatabaseConversationTable` (diferente a Stacks 1-2)

## üîß Configuraci√≥n Avanzada

### **üåç Variables de Entorno**

**Lambda ETL-1**:
```bash
S3_BUCKET_NAME=cat-prod-normalize-reports
DYNAMODB_TABLE_NAME=cat-prod-catia-conversations-table  
PROJECT_ID=P0260
ENVIRONMENT=PROD
CLIENT=CAT
```

**Lambda Tokens** (Stack 3 - Independiente):
```bash
S3_BUCKET_NAME=cat-prod-normalize-reports
S3_OUTPUT_PREFIX=tokens-analysis/
DYNAMODB_TABLE_NAME=BedrockChatStack-DatabaseConversationTable03F3FD7A-VCTDHISEE1NF
ATHENA_DATABASE=cat_prod_analytics_db
ATHENA_WORKGROUP=wg-cat-prod-analytics
ATHENA_OUTPUT_LOCATION=s3://cat-prod-normalize-reports/athena/results/
BEDROCK_MODEL=claude-3-5-sonnet-20240620-v1:0
AWS_REGION=us-east-1
```

**Glue Job ETL-2**:
```bash
--INPUT_PREFIX=reports/etl-process1/
--OUTPUT_PREFIX=reports/etl-process2/
--BUCKET_NAME=cat-prod-normalize-reports
```

### **üìä Configuraci√≥n de Horarios**

```typescript
// EventBridge Schedule - Ambos stacks
schedule: events.Schedule.expression('cron(30 4 * * ? *)') // 11:30 PM Colombia
```

### **üè∑Ô∏è Sistema de Tags para Cost Explorer**

| Tag | Valor | Prop√≥sito |
|-----|-------|----------|
| `BillingTag` | `ETL-LAMBDA-ETL1`, `ETL-GLUE-ETL2`, `TOKENS-BEDROCK-CLAUDE` | Separaci√≥n de costos por componente |
| `CostCenter` | `DATA-ANALYTICS`, `BEDROCK-ANALYTICS` | Centro de costos |
| `Project` | `CAT-PROD-NORMALIZE`, `CAT-PROD-TOKENS-BEDROCK` | Identificaci√≥n proyecto |
| `Environment` | `PROD` | Ambiente |
| `ETLComponent` | `ETL-1`, `ETL-2`, `TOKENS-BEDROCK-ANALYSIS` | Componente del pipeline |
| `DataSource` | `DynamoDB-CATIA`, `DynamoDB-BEDROCK`, `S3-CSV` | Fuente de datos |
| `DataTarget` | `S3-CSV`, `S3-PARQUET`, `S3-TOKENS` | Destino de datos |
| `Owner` | `DataEngineering`, `BedrockAnalytics` | Propietario t√©cnico |

## üß™ Testing y Validaci√≥n

### **üîç Tests Locales**

```bash
# Tests unitarios CDK
npm run test

# Test funci√≥n tokens Bedrock local
python test_token_functions.py

# Test Lambda ETL-1 local (requiere credenciales AWS)
cd lambda/etl-process1
python -c "
import lambda_function
result = lambda_function.lambda_handler({}, {})
print(result)
"

# Test Lambda Tokens Bedrock local (requiere credenciales AWS)
cd lambda/tokens-process
python -c "
import tokens_lambda
result = tokens_lambda.lambda_handler({}, {})
print(result)
"

# Validar script Glue local (requiere Spark)
cd lambda/etl-process2  
python glue_job_script.py
```

### **üìä Monitoreo en Producci√≥n**

#### **CloudWatch Logs**
```bash
# Logs ETL-1 Lambda
aws logs describe-log-groups --log-group-name-prefix "/aws/lambda/cat-prod-lambda-normalize"

# Logs ETL-2 Glue
aws logs describe-log-groups --log-group-name-prefix "/aws-glue/jobs/cat-prod-etl2-parquet"

# Logs Tokens Lambda  
aws logs describe-log-groups --log-group-name-prefix "/aws/lambda/cat-prod-lambda-tokens"
```

#### **M√©tricas Clave por Stack**
| M√©trica | ETL-1 Lambda | ETL-2 Glue | Tokens Bedrock Lambda |
|---------|--------------|------------|----------------------|
| **Duration** | < 15 min | < 10 min | < 1 min |
| **Memory** | < 1024 MB | N/A (Spark) | < 512 MB |
| **Errors** | 0% | 0% | 0% |
| **Cost/d√≠a** | ~$0.10 | ~$0.50 | ~$0.02 |
| **Data Source** | DynamoDB Catia | S3 CSV | **DynamoDB Bedrock** |

#### **Validaci√≥n de Datos**
```sql
-- Athena: Validar ETL-2 output
SELECT 
    COUNT(*) as total_usuarios,
    MIN(fecha_primera_conversacion) as fecha_min,
    MAX(fecha_primera_conversacion) as fecha_max,
    AVG(numero_conversaciones) as promedio_conversaciones
FROM cat_prod_analytics_db.data;

-- Athena: Validar tokens analysis Bedrock
SELECT 
    DATE(fecha) as dia,
    COUNT(*) as conversaciones_bedrock,
    SUM(tokens_total) as tokens_totales_claude,
    SUM(costo_estimado_usd) as costo_diario_bedrock,
    modelo
FROM cat_prod_analytics_db.tokens_analysis 
GROUP BY DATE(fecha), modelo
ORDER BY dia DESC;
```

## ‚öôÔ∏è Comandos de Gesti√≥n

### **üìã Comandos CDK Principales**

| Comando | Descripci√≥n | Uso |
|---------|-------------|-----|
| `npm run build` | Compilar TypeScript | Antes de deploy |
| `npm run watch` | Compilaci√≥n autom√°tica | Desarrollo |
| `npx cdk synth` | Generar CloudFormation | Validaci√≥n |
| `npx cdk deploy --all` | Desplegar todos los stacks | Deploy completo |
| `npx cdk diff <stack>` | Ver cambios pendientes | Pre-deploy |
| `npx cdk destroy --all` | Eliminar todos los recursos | Cleanup |

### **üîÑ Operaciones por Stack**

```bash
# Deploy selectivo
npx cdk deploy cat-prod-normalize-stack    # Solo ETL-1
npx cdk deploy cat-prod-etl2-stack         # Solo ETL-2  
npx cdk deploy cat-prod-tokens-stack       # Solo Tokens

# Logs en tiempo real
aws logs tail /aws/lambda/cat-prod-lambda-normalize --follow
aws logs tail /aws-glue/jobs/cat-prod-etl2-parquet --follow

# Trigger manual de prueba
aws lambda invoke \
  --function-name cat-prod-lambda-normalize \
  --payload '{}' \
  response.json

# Estado del Glue Job
aws glue get-job-runs --job-name cat-prod-etl2-parquet

# Verificar Crawler
aws glue get-crawler --name curated-crawler
```

### **üìä Consultas Athena de Validaci√≥n**

```sql
-- Verificar integridad datos ETL-1 ‚Üí ETL-2
SELECT 
    table_name,
    column_name,
    data_type,
    is_nullable
FROM information_schema.columns 
WHERE table_schema = 'cat_prod_analytics_db'
ORDER BY table_name, ordinal_position;

-- KPIs del pipeline
SELECT 
    'Total Usuarios' as metrica,
    COUNT(DISTINCT usuario_id) as valor
FROM cat_prod_analytics_db.data
UNION ALL
SELECT 
    'Total Conversaciones',
    SUM(numero_conversaciones)
FROM cat_prod_analytics_db.data;
```

---
