# ğŸ“ Estructura de Carpetas ETL - Cat Prod Normalize

## ğŸ—ï¸ OrganizaciÃ³n General

```
lambda/
â”œâ”€â”€ etl-process1/           # ğŸ”„ ETL-1: Lambda â†’ CSV
â”‚   â”œâ”€â”€ lambda_function.py  # FunciÃ³n Lambda principal
â”‚   â””â”€â”€ requirements.txt    # Dependencias de Lambda
â””â”€â”€ etl-process2/           # ğŸ”„ ETL-2: Glue â†’ Parquet  
    â”œâ”€â”€ glue_job_script.py  # Script de AWS Glue
    â””â”€â”€ requirements.txt    # Dependencias de Glue
```

## ğŸ“Š ETL-1 (Lambda Process)

**UbicaciÃ³n**: `lambda/etl-process1/`

**PropÃ³sito**: 
- Extrae datos de DynamoDB
- Procesa y normaliza informaciÃ³n de usuarios
- Genera archivos CSV en S3

**Componentes**:
- `lambda_function.py`: LÃ³gica principal de extracciÃ³n y transformaciÃ³n
- `requirements.txt`: Dependencias Python (pandas, boto3, etc.)

**Output**: `s3://cat-prod-normalize-reports/reports/etl-process1/data_YYYYMMDD.csv`

## âš¡ ETL-2 (Glue Process)

**UbicaciÃ³n**: `lambda/etl-process2/`

**PropÃ³sito**:
- Lee archivos CSV generados por ETL-1
- Transforma a formato Parquet optimizado
- Archivo Ãºnico para consultas eficientes

**Componentes**:
- `glue_job_script.py`: Script de Glue con lÃ³gica de transformaciÃ³n
- `requirements.txt`: Dependencias adicionales para Glue

**Input**: `s3://cat-prod-normalize-reports/reports/etl-process1/`
**Output**: `s3://cat-prod-normalize-reports/reports/etl-process2/data.parquet`

## ğŸ”§ ConfiguraciÃ³n de Paths

### CDK Stack Configuration

Los paths se configuran automÃ¡ticamente en:

1. **ETL-1 Lambda**: `lib/stacks/cat-prod-normalize-stack.ts`
   ```typescript
   code: lambda.Code.fromAsset('lambda/etl-process1', {
     exclude: ['requirements.txt', '*.pyc', '__pycache__']
   })
   ```

2. **ETL-2 Glue Script**: `bin/cat-prod-normalize.ts`
   ```typescript
   glueScriptS3Uri: 's3://cat-prod-normalize-reports/scripts/etl-process2/glue_job_script.py'
   ```

### S3 Bucket Structure

```
s3://cat-prod-normalize-reports/
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ etl-process1/           # CSV files (Lambda output)
â”‚   â””â”€â”€ etl-process2/           # Parquet files (Glue output)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ etl-process2/           # Glue script storage
â””â”€â”€ athena/
    â””â”€â”€ results/                # Query results
```

## ğŸš€ Deployment

1. **Compilar proyecto**:
   ```bash
   npm run build
   ```

2. **Verificar sÃ­ntesis**:
   ```bash
   npx cdk synth
   ```

3. **Deploy ETL-1**:
   ```bash
   npx cdk deploy cat-prod-normalize-stack
   ```

4. **Deploy ETL-2**:
   ```bash
   npx cdk deploy cat-prod-etl2-stack
   ```

## ğŸ“‹ Logs y Monitoreo

- **ETL-1 Logs**: CloudWatch Logs - `/aws/lambda/cat-prod-lambda-normalize`
- **ETL-2 Logs**: CloudWatch Logs - `/aws-glue/jobs/`
- **S3 Events**: EventBridge para orquestaciÃ³n automÃ¡tica

## ğŸ”„ Flujo de Datos

1. **ETL-1**: DynamoDB â†’ Lambda â†’ CSV (S3)
2. **Trigger**: S3 Event â†’ EventBridge â†’ Glue Job Start
3. **ETL-2**: CSV â†’ Glue â†’ Parquet (S3)
4. **Analysis**: Parquet â†’ Athena â†’ Analytics

## ğŸ“ Notas de Desarrollo

- **SeparaciÃ³n clara**: Cada ETL tiene su propia carpeta y dependencias
- **ReutilizaciÃ³n**: Bucket S3 compartido entre procesos
- **Escalabilidad**: ETL-2 usa Spark para grandes volÃºmenes
- **Mantenimiento**: Scripts independientes para cada proceso
